{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fS4HK0RsN9s9"},"outputs":[],"source":["import tensorflow as tf\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BmXaGINkN9tA"},"outputs":[],"source":["# Function to remove any unnecessory small blobs\n","def remove_small_contours(rects):\n","    for i, (x,y,w,h) in enumerate(rects):\n","        if w*h < 50 :\n","            rects.pop(i)\n","    return rects"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiW4jZWtN9tC"},"outputs":[],"source":["def label(one_hot_arr):\n","    labels = '+ - 0 1 2 3 4 5 6 7 8 9 / *'.split()\n","    index = np.argmax(one_hot_arr)\n","    return labels[index]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"-PPcqLjlN9tD","executionInfo":{"status":"error","timestamp":1639674936925,"user_tz":-330,"elapsed":381,"user":{"displayName":"Abhijnya K G","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWMDaTipi3_x_K6blXdC-ilSMjeJCk9tBod3Sa6A=s64","userId":"04906903861360692334"}},"outputId":"35e0da50-40ef-474d-bc4f-6f4e48f51d17"},"outputs":[{"output_type":"error","ename":"DisabledFunctionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-fdd8f0a051d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpreprocessed_digits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"threshInv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshInv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"],"errorDetails":{"actions":[{"action":"open_snippet","actionText":"Search Snippets for cv2.imshow","snippetFilter":"cv2.imshow"}]}}],"source":["img = cv2.imread(\"/content/3.png\")\n","img = cv2.resize(img, (300,256), interpolation=cv2.INTER_AREA)\n","gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","# The images in the dataset have white background and black color for the digtis\n","# However its much more efficient to find contours on an image with BLACK BACKGROUND\n","# so we threshold the image in both BINARY(black img, white bg) and BINARY_INV(white img, black bg) and\n","# detect contours on \"threshInv\" and perform model prediction on \"thresh\"\n","_, threshInv = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n","_, thresh = cv2.threshold(gray,120, 255, cv2.THRESH_BINARY)\n","contours, _ = cv2.findContours(threshInv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","preprocessed_digits = []\n","\n","# Put all the rectangle coordinates of the contours in a list\n","rects = []\n","for c in contours:\n","    rects.append(cv2.boundingRect(c))\n","    \n","# remove small blobs if any    \n","processed_contours = remove_small_contours(rects)\n","# sort the contours from left to right so that the model predicts the digtis/operators in order\n","sorted_contours = sorted(processed_contours)\n","\n","for (x,y,w,h) in sorted_contours:\n","    # speical case for - sign. Pad top and bottom \n","    if w>2*h:\n","        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n","        digit = thresh[y:y+h, x:x+w]\n","        padded_digit = np.pad(digit, ((15,15),(0,0)), mode='constant', constant_values=255)\n","        padded_digit = cv2.resize(padded_digit, (32,32), interpolation=cv2.INTER_AREA)\n","        \n","    else:\n","        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n","        # extract the digit\n","        digit = thresh[y:y+h, x:x+w]\n","        # pad some white pixels to the extracted image for better prediction results\n","        resized_digit = cv2.resize(digit, (26,26), interpolation=cv2.INTER_AREA)\n","        padded_digit = np.pad(resized_digit, ((3,3),(3,3)), mode='constant', constant_values=255)\n","    \n","    preprocessed_digits.append(padded_digit)\n","\n","cv2.imshow(\"img\", img)\n","cv2.imshow(\"threshInv\", threshInv)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWmW6Ua8N9tF"},"outputs":[],"source":["model_math = tf.keras.models.load_model(\"num_detect99.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zY5Mplj5N9tG"},"outputs":[],"source":["_, ax = plt.subplots(1, len(preprocessed_digits), figsize=(6,6))\n","res = []\n","\n","for i in range (len(preprocessed_digits)):\n","    \n","    digit = preprocessed_digits[i]\n","    prediction = model_math.predict(digit.reshape(1,32,32,1))\n","    ax[i].imshow(digit, cmap ='gray')\n","    ax[i].set_title(label(prediction))\n","    ax[i].axis(\"off\")\n","    res.append(label(prediction))\n","    \n","plt.show()\n","print(\"Result: \", eval(\"\".join(res)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6-t78DPN9tI"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Math Eqs.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}